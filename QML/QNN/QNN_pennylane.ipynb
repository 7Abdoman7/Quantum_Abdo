{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components = 20\n",
    "# PCA_model = PCA(n_components=n_components)\n",
    "# X = PCA_model.fit_transform(X)\n",
    "\n",
    "# explained_variance = PCA_model.explained_variance_ratio_\n",
    "\n",
    "# sns.barplot(x=[i for i in range(1, len(explained_variance)+1)], y=explained_variance)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdo\\Anaconda3\\envs\\Quantum\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Abdo\\Anaconda3\\envs\\Quantum\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "minmax_scale = MinMaxScaler((0, 2*np.pi)).fit(X)\n",
    "X_train = minmax_scale.transform(X_train)\n",
    "X_test = minmax_scale.transform(X_test)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_torch = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "X_test_torch  = torch.tensor(X_test,  dtype=torch.float32)\n",
    "y_test_torch  = torch.tensor(y_test.to_numpy(),  dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "test_dataset  = TensorDataset(X_test_torch,  y_test_torch)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 16\n",
    "n_layers = 1\n",
    "\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def qlayer(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=list(np.arange(n_qubits)), rotation='X')\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))    \n",
    "    return tuple(qml.expval(qml.PauliZ(i)) for i in range(n_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(len(X.T), 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 16)\n",
    "        self.scale = nn.Parameter(torch.tensor([2 * np.pi]))\n",
    "        self.qnn_weights = torch.rand(n_layers, n_qubits, 3) * 1e-3\n",
    "        self.output_layer = nn.Linear(n_qubits, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.tanh(self.fc4(x)) * self.scale\n",
    "        batch_size = x.size(0)\n",
    "        out = torch.empty((batch_size, n_qubits), dtype=torch.float32)\n",
    "        for batch_index in range(batch_size):\n",
    "            expval_tensors = qlayer(x[batch_index], self.qnn_weights)\n",
    "            expval_floats = [t.item() for t in expval_tensors]\n",
    "            out[batch_index] = torch.tensor(expval_floats)\n",
    "        x = self.output_layer(out)  \n",
    "        return x\n",
    "\n",
    "model = HybridClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(len(X.T), 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 16)\n",
    "        self.output_layer = nn.Linear(16, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "model = HybridClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        #X, y = X.to(torch_device), y.to(torch_device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    pred = None\n",
    "    X = None\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "           # X, y = X.to(torch_device), y.to(torch_device)\n",
    "            pred = model(X)\n",
    "            predicted_label = torch.argmax(pred, dim=1)\n",
    "            correct += torch.count_nonzero(predicted_label == y)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    print(f\"Accuracy: {correct / (len(dataloader) * batch_size) * 100}\")\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training\n",
      "--------------------------\n",
      "Epoch 1\n",
      "--------------------------\n",
      "loss: 2.288773 [   32/56000\n",
      "loss: 1.244923 [ 3232/56000\n",
      "loss: 0.616738 [ 6432/56000\n",
      "loss: 0.614512 [ 9632/56000\n",
      "loss: 0.362705 [12832/56000\n",
      "loss: 0.602500 [16032/56000\n",
      "loss: 0.363992 [19232/56000\n",
      "loss: 0.964508 [22432/56000\n",
      "loss: 0.208646 [25632/56000\n",
      "loss: 0.192730 [28832/56000\n",
      "loss: 0.256801 [32032/56000\n",
      "loss: 0.255391 [35232/56000\n",
      "loss: 0.311931 [38432/56000\n",
      "loss: 0.350276 [41632/56000\n",
      "loss: 0.076499 [44832/56000\n",
      "loss: 0.106581 [48032/56000\n",
      "loss: 0.073957 [51232/56000\n",
      "loss: 0.103202 [54432/56000\n",
      "Accuracy: 94.12100219726562\n",
      "Avg loss: 0.206725 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------\n",
      "loss: 0.169850 [   32/56000\n",
      "loss: 0.405935 [ 3232/56000\n",
      "loss: 0.082833 [ 6432/56000\n",
      "loss: 0.210112 [ 9632/56000\n",
      "loss: 0.030682 [12832/56000\n",
      "loss: 0.315814 [16032/56000\n",
      "loss: 0.027142 [19232/56000\n",
      "loss: 0.433003 [22432/56000\n",
      "loss: 0.028945 [25632/56000\n",
      "loss: 0.048435 [28832/56000\n",
      "loss: 0.055345 [32032/56000\n",
      "loss: 0.204920 [35232/56000\n",
      "loss: 0.166778 [38432/56000\n",
      "loss: 0.256130 [41632/56000\n",
      "loss: 0.159560 [44832/56000\n",
      "loss: 0.360548 [48032/56000\n",
      "loss: 0.236310 [51232/56000\n",
      "loss: 0.277182 [54432/56000\n",
      "Accuracy: 95.18407440185547\n",
      "Avg loss: 0.176932 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------\n",
      "loss: 0.033867 [   32/56000\n",
      "loss: 0.038993 [ 3232/56000\n",
      "loss: 0.069076 [ 6432/56000\n",
      "loss: 0.048698 [ 9632/56000\n",
      "loss: 0.147882 [12832/56000\n",
      "loss: 0.117995 [16032/56000\n",
      "loss: 0.079652 [19232/56000\n",
      "loss: 0.054323 [22432/56000\n",
      "loss: 0.333520 [25632/56000\n",
      "loss: 0.033231 [28832/56000\n",
      "loss: 0.108746 [32032/56000\n",
      "loss: 0.123535 [35232/56000\n",
      "loss: 0.032992 [38432/56000\n",
      "loss: 0.144874 [41632/56000\n",
      "loss: 0.266821 [44832/56000\n",
      "loss: 0.048902 [48032/56000\n",
      "loss: 0.463192 [51232/56000\n",
      "loss: 0.138977 [54432/56000\n",
      "Accuracy: 96.14726257324219\n",
      "Avg loss: 0.146389 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------\n",
      "loss: 0.061577 [   32/56000\n",
      "loss: 0.046383 [ 3232/56000\n",
      "loss: 0.078751 [ 6432/56000\n",
      "loss: 0.006231 [ 9632/56000\n",
      "loss: 0.433798 [12832/56000\n",
      "loss: 0.020798 [16032/56000\n",
      "loss: 0.048341 [19232/56000\n",
      "loss: 0.105486 [22432/56000\n",
      "loss: 0.097558 [25632/56000\n",
      "loss: 0.097189 [28832/56000\n",
      "loss: 0.079313 [32032/56000\n",
      "loss: 0.025782 [35232/56000\n",
      "loss: 0.176277 [38432/56000\n",
      "loss: 0.041841 [41632/56000\n",
      "loss: 0.046809 [44832/56000\n",
      "loss: 0.076594 [48032/56000\n",
      "loss: 0.007927 [51232/56000\n",
      "loss: 0.057696 [54432/56000\n",
      "Accuracy: 96.58961486816406\n",
      "Avg loss: 0.132006 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------\n",
      "loss: 0.004669 [   32/56000\n",
      "loss: 0.014122 [ 3232/56000\n",
      "loss: 0.049777 [ 6432/56000\n",
      "loss: 0.083787 [ 9632/56000\n",
      "loss: 0.190688 [12832/56000\n",
      "loss: 0.081900 [16032/56000\n",
      "loss: 0.002758 [19232/56000\n",
      "loss: 0.153538 [22432/56000\n",
      "loss: 0.005918 [25632/56000\n",
      "loss: 0.049776 [28832/56000\n",
      "loss: 0.034680 [32032/56000\n",
      "loss: 0.129886 [35232/56000\n",
      "loss: 0.141738 [38432/56000\n",
      "loss: 0.006840 [41632/56000\n",
      "loss: 0.074612 [44832/56000\n",
      "loss: 0.077450 [48032/56000\n",
      "loss: 0.257147 [51232/56000\n",
      "loss: 0.036399 [54432/56000\n",
      "Accuracy: 96.53253173828125\n",
      "Avg loss: 0.136550 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------\n",
      "loss: 0.011679 [   32/56000\n",
      "loss: 0.002482 [ 3232/56000\n",
      "loss: 0.031207 [ 6432/56000\n",
      "loss: 0.084228 [ 9632/56000\n",
      "loss: 0.025587 [12832/56000\n",
      "loss: 0.061565 [16032/56000\n",
      "loss: 0.086501 [19232/56000\n",
      "loss: 0.019932 [22432/56000\n",
      "loss: 0.059807 [25632/56000\n",
      "loss: 0.003908 [28832/56000\n",
      "loss: 0.015266 [32032/56000\n",
      "loss: 0.018532 [35232/56000\n",
      "loss: 0.002926 [38432/56000\n",
      "loss: 0.021189 [41632/56000\n",
      "loss: 0.035051 [44832/56000\n",
      "loss: 0.012261 [48032/56000\n",
      "loss: 0.007138 [51232/56000\n",
      "loss: 0.026541 [54432/56000\n",
      "Accuracy: 96.810791015625\n",
      "Avg loss: 0.137389 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------\n",
      "loss: 0.005306 [   32/56000\n",
      "loss: 0.012055 [ 3232/56000\n",
      "loss: 0.024534 [ 6432/56000\n",
      "loss: 0.018621 [ 9632/56000\n",
      "loss: 0.003187 [12832/56000\n",
      "loss: 0.003443 [16032/56000\n",
      "loss: 0.012565 [19232/56000\n",
      "loss: 0.157474 [22432/56000\n",
      "loss: 0.001689 [25632/56000\n",
      "loss: 0.006639 [28832/56000\n",
      "loss: 0.098434 [32032/56000\n",
      "loss: 0.023747 [35232/56000\n",
      "loss: 0.045415 [38432/56000\n",
      "loss: 0.011266 [41632/56000\n",
      "loss: 0.018786 [44832/56000\n",
      "loss: 0.009215 [48032/56000\n",
      "loss: 0.013812 [51232/56000\n",
      "loss: 0.039883 [54432/56000\n",
      "Accuracy: 96.74657440185547\n",
      "Avg loss: 0.139477 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------\n",
      "loss: 0.018299 [   32/56000\n",
      "loss: 0.003436 [ 3232/56000\n",
      "loss: 0.009322 [ 6432/56000\n",
      "loss: 0.001053 [ 9632/56000\n",
      "loss: 0.001955 [12832/56000\n",
      "loss: 0.007075 [16032/56000\n",
      "loss: 0.014391 [19232/56000\n",
      "loss: 0.005391 [22432/56000\n",
      "loss: 0.016109 [25632/56000\n",
      "loss: 0.002350 [28832/56000\n",
      "loss: 0.010613 [32032/56000\n",
      "loss: 0.000612 [35232/56000\n",
      "loss: 0.010478 [38432/56000\n",
      "loss: 0.011201 [41632/56000\n",
      "loss: 0.005906 [44832/56000\n",
      "loss: 0.005630 [48032/56000\n",
      "loss: 0.174330 [51232/56000\n",
      "loss: 0.034602 [54432/56000\n",
      "Accuracy: 96.73944091796875\n",
      "Avg loss: 0.145308 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------\n",
      "loss: 0.002044 [   32/56000\n",
      "loss: 0.002806 [ 3232/56000\n",
      "loss: 0.003690 [ 6432/56000\n",
      "loss: 0.006824 [ 9632/56000\n",
      "loss: 0.001958 [12832/56000\n",
      "loss: 0.001637 [16032/56000\n",
      "loss: 0.000897 [19232/56000\n",
      "loss: 0.009857 [22432/56000\n",
      "loss: 0.232856 [25632/56000\n",
      "loss: 0.003040 [28832/56000\n",
      "loss: 0.007612 [32032/56000\n",
      "loss: 0.015119 [35232/56000\n",
      "loss: 0.047426 [38432/56000\n",
      "loss: 0.005095 [41632/56000\n",
      "loss: 0.004116 [44832/56000\n",
      "loss: 0.031641 [48032/56000\n",
      "loss: 0.031908 [51232/56000\n",
      "loss: 0.013712 [54432/56000\n",
      "Accuracy: 97.06050109863281\n",
      "Avg loss: 0.151912 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------\n",
      "loss: 0.017825 [   32/56000\n",
      "loss: 0.000293 [ 3232/56000\n",
      "loss: 0.000234 [ 6432/56000\n",
      "loss: 0.001286 [ 9632/56000\n",
      "loss: 0.005314 [12832/56000\n",
      "loss: 0.068455 [16032/56000\n",
      "loss: 0.007298 [19232/56000\n",
      "loss: 0.001635 [22432/56000\n",
      "loss: 0.005718 [25632/56000\n",
      "loss: 0.031867 [28832/56000\n",
      "loss: 0.063707 [32032/56000\n",
      "loss: 0.001600 [35232/56000\n",
      "loss: 0.003909 [38432/56000\n",
      "loss: 0.009223 [41632/56000\n",
      "loss: 0.001312 [44832/56000\n",
      "loss: 0.003202 [48032/56000\n",
      "loss: 0.129791 [51232/56000\n",
      "loss: 0.140511 [54432/56000\n",
      "Accuracy: 96.91067504882812\n",
      "Avg loss: 0.160409 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------\n",
      "loss: 0.002610 [   32/56000\n",
      "loss: 0.015593 [ 3232/56000\n",
      "loss: 0.010788 [ 6432/56000\n",
      "loss: 0.000814 [ 9632/56000\n",
      "loss: 0.001426 [12832/56000\n",
      "loss: 0.006053 [16032/56000\n",
      "loss: 0.001958 [19232/56000\n",
      "loss: 0.002885 [22432/56000\n",
      "loss: 0.000288 [25632/56000\n",
      "loss: 0.003470 [28832/56000\n",
      "loss: 0.005697 [32032/56000\n",
      "loss: 0.001792 [35232/56000\n",
      "loss: 0.004037 [38432/56000\n",
      "loss: 0.070936 [41632/56000\n",
      "loss: 0.001114 [44832/56000\n",
      "loss: 0.001717 [48032/56000\n",
      "loss: 0.012734 [51232/56000\n",
      "loss: 0.003296 [54432/56000\n",
      "Accuracy: 97.33161926269531\n",
      "Avg loss: 0.142937 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------\n",
      "loss: 0.000769 [   32/56000\n",
      "loss: 0.003499 [ 3232/56000\n",
      "loss: 0.000155 [ 6432/56000\n",
      "loss: 0.045316 [ 9632/56000\n",
      "loss: 0.000716 [12832/56000\n",
      "loss: 0.000566 [16032/56000\n",
      "loss: 0.003019 [19232/56000\n",
      "loss: 0.000144 [22432/56000\n",
      "loss: 0.000070 [25632/56000\n",
      "loss: 0.000133 [28832/56000\n",
      "loss: 0.002844 [32032/56000\n",
      "loss: 0.000237 [35232/56000\n",
      "loss: 0.003213 [38432/56000\n",
      "loss: 0.000843 [41632/56000\n",
      "loss: 0.000122 [44832/56000\n",
      "loss: 0.001526 [48032/56000\n",
      "loss: 0.000375 [51232/56000\n",
      "loss: 0.000222 [54432/56000\n",
      "Accuracy: 97.44577026367188\n",
      "Avg loss: 0.147633 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------\n",
      "loss: 0.002638 [   32/56000\n",
      "loss: 0.005583 [ 3232/56000\n",
      "loss: 0.000861 [ 6432/56000\n",
      "loss: 0.006189 [ 9632/56000\n",
      "loss: 0.000518 [12832/56000\n",
      "loss: 0.000178 [16032/56000\n",
      "loss: 0.000523 [19232/56000\n",
      "loss: 0.001714 [22432/56000\n",
      "loss: 0.000835 [25632/56000\n",
      "loss: 0.000515 [28832/56000\n",
      "loss: 0.010059 [32032/56000\n",
      "loss: 0.000110 [35232/56000\n",
      "loss: 0.000556 [38432/56000\n",
      "loss: 0.000170 [41632/56000\n",
      "loss: 0.000316 [44832/56000\n",
      "loss: 0.040936 [48032/56000\n",
      "loss: 0.004753 [51232/56000\n",
      "loss: 0.000095 [54432/56000\n",
      "Accuracy: 97.46004486083984\n",
      "Avg loss: 0.155709 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------\n",
      "loss: 0.000794 [   32/56000\n",
      "loss: 0.000626 [ 3232/56000\n",
      "loss: 0.000455 [ 6432/56000\n",
      "loss: 0.001510 [ 9632/56000\n",
      "loss: 0.000078 [12832/56000\n",
      "loss: 0.000144 [16032/56000\n",
      "loss: 0.000418 [19232/56000\n",
      "loss: 0.000340 [22432/56000\n",
      "loss: 0.002067 [25632/56000\n",
      "loss: 0.001852 [28832/56000\n",
      "loss: 0.000369 [32032/56000\n",
      "loss: 0.000336 [35232/56000\n",
      "loss: 0.000329 [38432/56000\n",
      "loss: 0.000267 [41632/56000\n",
      "loss: 0.002279 [44832/56000\n",
      "loss: 0.000327 [48032/56000\n",
      "loss: 0.000086 [51232/56000\n",
      "loss: 0.000219 [54432/56000\n",
      "Accuracy: 97.42436981201172\n",
      "Avg loss: 0.168871 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------\n",
      "loss: 0.000265 [   32/56000\n",
      "loss: 0.000021 [ 3232/56000\n",
      "loss: 0.001470 [ 6432/56000\n",
      "loss: 0.000108 [ 9632/56000\n",
      "loss: 0.000523 [12832/56000\n",
      "loss: 0.010454 [16032/56000\n",
      "loss: 0.000899 [19232/56000\n",
      "loss: 0.000193 [22432/56000\n",
      "loss: 0.000032 [25632/56000\n",
      "loss: 0.000061 [28832/56000\n",
      "loss: 0.013407 [32032/56000\n",
      "loss: 0.001610 [35232/56000\n",
      "loss: 0.000187 [38432/56000\n",
      "loss: 0.003571 [41632/56000\n",
      "loss: 0.004453 [44832/56000\n",
      "loss: 0.000646 [48032/56000\n",
      "loss: 0.000309 [51232/56000\n",
      "loss: 0.000215 [54432/56000\n",
      "Accuracy: 97.48857879638672\n",
      "Avg loss: 0.174016 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------\n",
      "loss: 0.000715 [   32/56000\n",
      "loss: 0.000896 [ 3232/56000\n",
      "loss: 0.000137 [ 6432/56000\n",
      "loss: 0.000287 [ 9632/56000\n",
      "loss: 0.000201 [12832/56000\n",
      "loss: 0.007375 [16032/56000\n",
      "loss: 0.000101 [19232/56000\n",
      "loss: 0.000254 [22432/56000\n",
      "loss: 0.000708 [25632/56000\n",
      "loss: 0.000059 [28832/56000\n",
      "loss: 0.000411 [32032/56000\n",
      "loss: 0.000346 [35232/56000\n",
      "loss: 0.000153 [38432/56000\n",
      "loss: 0.000156 [41632/56000\n",
      "loss: 0.005660 [44832/56000\n",
      "loss: 0.003143 [48032/56000\n",
      "loss: 0.000152 [51232/56000\n",
      "loss: 0.000020 [54432/56000\n",
      "Accuracy: 97.51712036132812\n",
      "Avg loss: 0.179664 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------\n",
      "loss: 0.000152 [   32/56000\n",
      "loss: 0.000213 [ 3232/56000\n",
      "loss: 0.000274 [ 6432/56000\n",
      "loss: 0.000038 [ 9632/56000\n",
      "loss: 0.000242 [12832/56000\n",
      "loss: 0.000163 [16032/56000\n",
      "loss: 0.000130 [19232/56000\n",
      "loss: 0.000557 [22432/56000\n",
      "loss: 0.000113 [25632/56000\n",
      "loss: 0.000058 [28832/56000\n",
      "loss: 0.000081 [32032/56000\n",
      "loss: 0.000351 [35232/56000\n",
      "loss: 0.000215 [38432/56000\n",
      "loss: 0.001055 [41632/56000\n",
      "loss: 0.000042 [44832/56000\n",
      "loss: 0.000029 [48032/56000\n",
      "loss: 0.000057 [51232/56000\n",
      "loss: 0.000009 [54432/56000\n",
      "Accuracy: 97.5099868774414\n",
      "Avg loss: 0.181075 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------\n",
      "loss: 0.000821 [   32/56000\n",
      "loss: 0.000286 [ 3232/56000\n",
      "loss: 0.000013 [ 6432/56000\n",
      "loss: 0.000306 [ 9632/56000\n",
      "loss: 0.000025 [12832/56000\n",
      "loss: 0.000220 [16032/56000\n",
      "loss: 0.000019 [19232/56000\n",
      "loss: 0.000021 [22432/56000\n",
      "loss: 0.001066 [25632/56000\n",
      "loss: 0.000020 [28832/56000\n",
      "loss: 0.000233 [32032/56000\n",
      "loss: 0.000002 [35232/56000\n",
      "loss: 0.000010 [38432/56000\n",
      "loss: 0.000178 [41632/56000\n",
      "loss: 0.000503 [44832/56000\n",
      "loss: 0.000614 [48032/56000\n",
      "loss: 0.000048 [51232/56000\n",
      "loss: 0.000236 [54432/56000\n",
      "Accuracy: 97.54566192626953\n",
      "Avg loss: 0.182989 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------\n",
      "loss: 0.000037 [   32/56000\n",
      "loss: 0.000003 [ 3232/56000\n",
      "loss: 0.000894 [ 6432/56000\n",
      "loss: 0.000448 [ 9632/56000\n",
      "loss: 0.000144 [12832/56000\n",
      "loss: 0.000016 [16032/56000\n",
      "loss: 0.000328 [19232/56000\n",
      "loss: 0.000414 [22432/56000\n",
      "loss: 0.000315 [25632/56000\n",
      "loss: 0.000019 [28832/56000\n",
      "loss: 0.000733 [32032/56000\n",
      "loss: 0.000259 [35232/56000\n",
      "loss: 0.000424 [38432/56000\n",
      "loss: 0.000198 [41632/56000\n",
      "loss: 0.000259 [44832/56000\n",
      "loss: 0.000750 [48032/56000\n",
      "loss: 0.000021 [51232/56000\n",
      "loss: 0.000009 [54432/56000\n",
      "Accuracy: 97.5741958618164\n",
      "Avg loss: 0.184876 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------\n",
      "loss: 0.007097 [   32/56000\n",
      "loss: 0.000078 [ 3232/56000\n",
      "loss: 0.000064 [ 6432/56000\n",
      "loss: 0.000255 [ 9632/56000\n",
      "loss: 0.000208 [12832/56000\n",
      "loss: 0.000290 [16032/56000\n",
      "loss: 0.001858 [19232/56000\n",
      "loss: 0.000020 [22432/56000\n",
      "loss: 0.000144 [25632/56000\n",
      "loss: 0.000358 [28832/56000\n",
      "loss: 0.000621 [32032/56000\n",
      "loss: 0.000065 [35232/56000\n",
      "loss: 0.000159 [38432/56000\n",
      "loss: 0.000102 [41632/56000\n",
      "loss: 0.001003 [44832/56000\n",
      "loss: 0.000910 [48032/56000\n",
      "loss: 0.001564 [51232/56000\n",
      "loss: 0.000038 [54432/56000\n",
      "Accuracy: 97.55992889404297\n",
      "Avg loss: 0.186232 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------\n",
      "loss: 0.000432 [   32/56000\n",
      "loss: 0.000115 [ 3232/56000\n",
      "loss: 0.000866 [ 6432/56000\n",
      "loss: 0.000768 [ 9632/56000\n",
      "loss: 0.000017 [12832/56000\n",
      "loss: 0.000217 [16032/56000\n",
      "loss: 0.000028 [19232/56000\n",
      "loss: 0.000329 [22432/56000\n",
      "loss: 0.000038 [25632/56000\n",
      "loss: 0.000109 [28832/56000\n",
      "loss: 0.000107 [32032/56000\n",
      "loss: 0.000265 [35232/56000\n",
      "loss: 0.000384 [38432/56000\n",
      "loss: 0.000532 [41632/56000\n",
      "loss: 0.000734 [44832/56000\n",
      "loss: 0.000210 [48032/56000\n",
      "loss: 0.000049 [51232/56000\n",
      "loss: 0.000128 [54432/56000\n",
      "Accuracy: 97.56706237792969\n",
      "Avg loss: 0.187914 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------\n",
      "loss: 0.000168 [   32/56000\n",
      "loss: 0.000055 [ 3232/56000\n",
      "loss: 0.000222 [ 6432/56000\n",
      "loss: 0.000092 [ 9632/56000\n",
      "loss: 0.000015 [12832/56000\n",
      "loss: 0.000006 [16032/56000\n",
      "loss: 0.000034 [19232/56000\n",
      "loss: 0.000077 [22432/56000\n",
      "loss: 0.000647 [25632/56000\n",
      "loss: 0.000448 [28832/56000\n",
      "loss: 0.000673 [32032/56000\n",
      "loss: 0.000089 [35232/56000\n",
      "loss: 0.000015 [38432/56000\n",
      "loss: 0.000443 [41632/56000\n",
      "loss: 0.000012 [44832/56000\n",
      "loss: 0.000001 [48032/56000\n",
      "loss: 0.000044 [51232/56000\n",
      "loss: 0.000079 [54432/56000\n",
      "Accuracy: 97.58132934570312\n",
      "Avg loss: 0.189298 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------\n",
      "loss: 0.000146 [   32/56000\n",
      "loss: 0.000316 [ 3232/56000\n",
      "loss: 0.001660 [ 6432/56000\n",
      "loss: 0.000046 [ 9632/56000\n",
      "loss: 0.000100 [12832/56000\n",
      "loss: 0.000084 [16032/56000\n",
      "loss: 0.000230 [19232/56000\n",
      "loss: 0.000567 [22432/56000\n",
      "loss: 0.000016 [25632/56000\n",
      "loss: 0.000485 [28832/56000\n",
      "loss: 0.000014 [32032/56000\n",
      "loss: 0.000050 [35232/56000\n",
      "loss: 0.000044 [38432/56000\n",
      "loss: 0.000632 [41632/56000\n",
      "loss: 0.001763 [44832/56000\n",
      "loss: 0.000019 [48032/56000\n",
      "loss: 0.000023 [51232/56000\n",
      "loss: 0.000053 [54432/56000\n",
      "Accuracy: 97.56706237792969\n",
      "Avg loss: 0.189462 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------\n",
      "loss: 0.003207 [   32/56000\n",
      "loss: 0.000058 [ 3232/56000\n",
      "loss: 0.000038 [ 6432/56000\n",
      "loss: 0.000086 [ 9632/56000\n",
      "loss: 0.000065 [12832/56000\n",
      "loss: 0.000106 [16032/56000\n",
      "loss: 0.000070 [19232/56000\n",
      "loss: 0.000008 [22432/56000\n",
      "loss: 0.000007 [25632/56000\n",
      "loss: 0.000725 [28832/56000\n",
      "loss: 0.000195 [32032/56000\n",
      "loss: 0.000316 [35232/56000\n",
      "loss: 0.000074 [38432/56000\n",
      "loss: 0.000046 [41632/56000\n",
      "loss: 0.000214 [44832/56000\n",
      "loss: 0.000053 [48032/56000\n",
      "loss: 0.000492 [51232/56000\n",
      "loss: 0.000310 [54432/56000\n",
      "Accuracy: 97.56706237792969\n",
      "Avg loss: 0.189651 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------\n",
      "loss: 0.000156 [   32/56000\n",
      "loss: 0.000367 [ 3232/56000\n",
      "loss: 0.000350 [ 6432/56000\n",
      "loss: 0.000006 [ 9632/56000\n",
      "loss: 0.000238 [12832/56000\n",
      "loss: 0.000678 [16032/56000\n",
      "loss: 0.000035 [19232/56000\n",
      "loss: 0.000190 [22432/56000\n",
      "loss: 0.001116 [25632/56000\n",
      "loss: 0.000060 [28832/56000\n",
      "loss: 0.000018 [32032/56000\n",
      "loss: 0.000575 [35232/56000\n",
      "loss: 0.000113 [38432/56000\n",
      "loss: 0.000027 [41632/56000\n",
      "loss: 0.000343 [44832/56000\n",
      "loss: 0.000169 [48032/56000\n",
      "loss: 0.000315 [51232/56000\n",
      "loss: 0.000214 [54432/56000\n",
      "Accuracy: 97.55992889404297\n",
      "Avg loss: 0.189842 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------\n",
      "loss: 0.000500 [   32/56000\n",
      "loss: 0.000331 [ 3232/56000\n",
      "loss: 0.000125 [ 6432/56000\n",
      "loss: 0.000066 [ 9632/56000\n",
      "loss: 0.000110 [12832/56000\n",
      "loss: 0.000141 [16032/56000\n",
      "loss: 0.000008 [19232/56000\n",
      "loss: 0.000174 [22432/56000\n",
      "loss: 0.000021 [25632/56000\n",
      "loss: 0.000211 [28832/56000\n",
      "loss: 0.000173 [32032/56000\n",
      "loss: 0.000054 [35232/56000\n",
      "loss: 0.000165 [38432/56000\n",
      "loss: 0.000051 [41632/56000\n",
      "loss: 0.000008 [44832/56000\n",
      "loss: 0.000176 [48032/56000\n",
      "loss: 0.000027 [51232/56000\n",
      "loss: 0.000022 [54432/56000\n",
      "Accuracy: 97.55992889404297\n",
      "Avg loss: 0.190000 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------\n",
      "loss: 0.000017 [   32/56000\n",
      "loss: 0.000175 [ 3232/56000\n",
      "loss: 0.004019 [ 6432/56000\n",
      "loss: 0.000110 [ 9632/56000\n",
      "loss: 0.000046 [12832/56000\n",
      "loss: 0.000091 [16032/56000\n",
      "loss: 0.000191 [19232/56000\n",
      "loss: 0.000293 [22432/56000\n",
      "loss: 0.000212 [25632/56000\n",
      "loss: 0.000120 [28832/56000\n",
      "loss: 0.000036 [32032/56000\n",
      "loss: 0.000089 [35232/56000\n",
      "loss: 0.000418 [38432/56000\n",
      "loss: 0.000737 [41632/56000\n",
      "loss: 0.000119 [44832/56000\n",
      "loss: 0.001264 [48032/56000\n",
      "loss: 0.000451 [51232/56000\n",
      "loss: 0.000874 [54432/56000\n",
      "Accuracy: 97.55992889404297\n",
      "Avg loss: 0.190192 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------\n",
      "loss: 0.000101 [   32/56000\n",
      "loss: 0.000145 [ 3232/56000\n",
      "loss: 0.000408 [ 6432/56000\n",
      "loss: 0.000244 [ 9632/56000\n",
      "loss: 0.000117 [12832/56000\n",
      "loss: 0.000461 [16032/56000\n",
      "loss: 0.000390 [19232/56000\n",
      "loss: 0.000815 [22432/56000\n",
      "loss: 0.000418 [25632/56000\n",
      "loss: 0.000033 [28832/56000\n",
      "loss: 0.000813 [32032/56000\n",
      "loss: 0.000401 [35232/56000\n",
      "loss: 0.000853 [38432/56000\n",
      "loss: 0.000042 [41632/56000\n",
      "loss: 0.000007 [44832/56000\n",
      "loss: 0.000290 [48032/56000\n",
      "loss: 0.000024 [51232/56000\n",
      "loss: 0.000629 [54432/56000\n",
      "Accuracy: 97.55992889404297\n",
      "Avg loss: 0.190351 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------\n",
      "loss: 0.000305 [   32/56000\n",
      "loss: 0.000458 [ 3232/56000\n",
      "loss: 0.000357 [ 6432/56000\n",
      "loss: 0.000155 [ 9632/56000\n",
      "loss: 0.000011 [12832/56000\n",
      "loss: 0.001391 [16032/56000\n",
      "loss: 0.000034 [19232/56000\n",
      "loss: 0.000103 [22432/56000\n",
      "loss: 0.000020 [25632/56000\n",
      "loss: 0.000020 [28832/56000\n",
      "loss: 0.000095 [32032/56000\n",
      "loss: 0.000747 [35232/56000\n",
      "loss: 0.000746 [38432/56000\n",
      "loss: 0.000182 [41632/56000\n",
      "loss: 0.000072 [44832/56000\n",
      "loss: 0.000016 [48032/56000\n",
      "loss: 0.000292 [51232/56000\n",
      "loss: 0.000149 [54432/56000\n",
      "Accuracy: 97.55992889404297\n",
      "Avg loss: 0.190365 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------\n",
      "loss: 0.000016 [   32/56000\n",
      "loss: 0.000170 [ 3232/56000\n",
      "loss: 0.000015 [ 6432/56000\n",
      "loss: 0.000308 [ 9632/56000\n",
      "loss: 0.002145 [12832/56000\n",
      "loss: 0.000076 [16032/56000\n",
      "loss: 0.001364 [19232/56000\n",
      "loss: 0.000187 [22432/56000\n",
      "loss: 0.000099 [25632/56000\n",
      "loss: 0.000020 [28832/56000\n",
      "loss: 0.000133 [32032/56000\n",
      "loss: 0.000374 [35232/56000\n",
      "loss: 0.000145 [38432/56000\n",
      "loss: 0.000009 [41632/56000\n",
      "loss: 0.000091 [44832/56000\n",
      "loss: 0.000034 [48032/56000\n",
      "loss: 0.000298 [51232/56000\n",
      "loss: 0.000060 [54432/56000\n",
      "Accuracy: 97.55992889404297\n",
      "Avg loss: 0.190381 \n",
      "\n",
      "Training took 2.81 minutes.\n",
      "Accuracy: 97.55992889404297\n",
      "Avg loss: 0.190381 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Before training\\n--------------------------\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n--------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loss = test_loop(test_loader, model, loss_fn)\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training took {elapsed_time/60:.2f} minutes.\")\n",
    "test_loop(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
